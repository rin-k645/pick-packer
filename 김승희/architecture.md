# Hadoop Spark Kafka

## Apache Hadoop

- 오픈 소스 빅데이터 처리 프레임워크
- 상용 서버 클러스터에서 분산 방식으로 대량의 데이터를 처리하도록 설계 되엉 ㅣㅆ다.
- 구조화, 반구조화, 비구조화 데이터를 저장하고 처리하는 비용 효율적이고 확장성이 뛰어난 데이터 수집 및 처리 기술
- 엄청 큰 데이터 세트를 작은 조각으로 나눈 다음 Hadoop Cluster를 생성하는 네트워크의 다른 서버나 노드로 보낼 수 있다. 그 후 할당된 데이터를 가지고 분석 작업을 동시에 한 후 최종 결과는 하나의 응집력있는 정보 단위로 최종 사용자에게 전송된다.
- 분산 컴퓨팅의 복잡성을 추상화함으로써 사용자가 사용하기 쉬운 API를 통해 시스템의 기능에 직접 액세스할 수 있도록 한다.
- 

Hadoop은 빅데이터 아키텍쳐. 데이터 저장 및 처리를 담당

Spark는 hadoop에 저장된 데이터에 대해 실시간 스트림 처리 또는 일괄 처리를 수행할 수 있는 인메모리 처리 엔진

Kafka는 스트리밍 데이터를 Hadoop으로 수집하거나 Spark를 통해 스트리밍 데이터를 실시간으로 처리하느네 사용할 수 있는 메시지 브로커

## 일반적인 빅데이터 파이프 라인

1. 다양한 data souce가 Kafka로 수집된다.
2. hadoop의 map reduce는 아키텍처 내에서 데이터를 저장하고 처리할 수 있다. 그 다음 Spark를 사용해 hadoop에 저장된 데이터에 대해 실시간 스트림 처리 또는 일괄 처리를 수행할 수 있다.
    
    → hadoop은 강력한 빅데이터 파이프라인 아키텍쳐를 제공하며, Spark및 Kafka가 그 위에서 작동할 수 있도록 한다.
    
    HDFS는 영구 데이터 스토리지를 제공한다.
    

## 람다 아키텍쳐

- 배치 및 스트림 처리 방법을 모두 활용해 대량의 데이터를 처리하도록 설계된 데이터 처리 아키텍쳐
- kafka는 input source
- hadoop은 배치 쿼리에 대한 초기 계산을 수행하는 영구 데이터 스토리지
    - 배치 처리 계층에서 실행됨
- Spark는 속도 계층에서 실시간 데이터 처리
- serving 계층은 일반적으로 대기 시간이 짧은 데이터 옵션 쿼리를 위해 NoSQL 데이터베이스에 의해 구성됨

## 카파 아키텍쳐

- 람다 아키텍쳐의 변행
- 속도와 단순성을 위해 배치 레이어를 버림
- 데이터는 한 번만 수집되고 도착하는 대로 처리되므로 먼저 저장할 필요가 없다
- kafka는 pub-sub 메시지 시스템으로 작동
- Spark는 실시간 스트리밍 레이어에 실행(배치 및 스트림 처리를 모두 처리할 수 있으므로)
- 하둡은 이 두 가지를 위한 ecosystem

### 잘 설계된 빅데이터 파이프라인이 중요한 이유

1. 대량의 데이터를 빠르고 효율적으로 수집 및 처리
2. 데이터를 안전하고 확실하게 저장
3. 실시간으로 데이터를 분석해 더 나은 결정
4. 데이터를 시각화해 트렌드와 패턴에 대한 인사이트
5. 다른 응용 프로그램에서 사용할 수 있는 완전한 빅데이터 아키텍쳐

 

참고

[https://nexocode.com/blog/posts/hadoop-spark-kafka-modern-big-data-architecture/](https://nexocode.com/blog/posts/hadoop-spark-kafka-modern-big-data-architecture/)